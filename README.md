<p align="center">
  <img src="A_digital_graphic_design_banner_advertises_a_softw.png" width="100%" alt="Mini AI Summarizer Banner"/>
</p>

<h1 align="center">ğŸ§  Mini AI Summarizer</h1>
<h3 align="center">Powered by Phi-3 + Ollama | Offline AI Summarization Chrome Extension</h3>

<p align="center">
  <a href="https://nodejs.org/"><img src="https://img.shields.io/badge/Node.js-18+-green?style=for-the-badge&logo=node.js"></a>
  <a href="https://ollama.ai/"><img src="https://img.shields.io/badge/Ollama-AI%20Model-blue?style=for-the-badge&logo=ai"></a>
  <a href="https://chrome.google.com/"><img src="https://img.shields.io/badge/Chrome-Extension-yellow?style=for-the-badge&logo=google-chrome"></a>
  <a href="https://github.com/yashrawat2362"><img src="https://img.shields.io/badge/Made%20by-Yash%20Rawat-black?style=for-the-badge"></a>
</p>

---

## ğŸŒŸ Overview

**Mini AI Summarizer** is a lightweight Chrome Extension that extracts and summarizes the main content of any webpage using a **local Phi-3 model via Ollama** â€” ensuring privacy, speed, and full offline capability.  
Itâ€™s your personal offline **Comet-like** AI summarizer.  

---

## ğŸš€ Features

- ğŸ§© **One-click summarization** from any webpage  
- âš™ï¸ **Local AI (Phi-3 / Ollama)** â€“ No API key or internet required  
- ğŸ§¼ **Smart text extraction** with DOM cleaner  
- âš¡ **Lightweight backend** built on Node.js + Express  
- ğŸ§­ **Fully customizable** (e.g., change AI models, tweak prompts)

---

## ğŸ—‚ï¸ Project Structure

ai-browser-prototype/
â”‚
â”œâ”€â”€ extension/
â”‚ â”œâ”€â”€ manifest.json
â”‚ â”œâ”€â”€ popup.html
â”‚ â”œâ”€â”€ popup.js
â”‚ â”œâ”€â”€ content.js
â”‚ â”œâ”€â”€ style.css
â”‚ â””â”€â”€ icons/
â”‚ â”œâ”€â”€ icon16.png
â”‚ â”œâ”€â”€ icon48.png
â”‚ â””â”€â”€ icon128.png
â”‚
â”œâ”€â”€ server/
â”‚ â”œâ”€â”€ server.js
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ package-lock.json
â”‚
â””â”€â”€ README.md


---

## âš™ï¸ Setup Instructions

### **1ï¸âƒ£ Prerequisites**
Make sure you have installed:
- [Node.js](https://nodejs.org/) (v18 or above)
- [Ollama](https://ollama.ai) (running locally)
- Google Chrome (for testing the extension)

---

### **2ï¸âƒ£ Install and Run Ollama Model**

Pull and serve the **Phi-3** model:
```bash
ollama pull phi3


(Optional) You can use Llama3 or Gemma2 instead:

ollama pull llama3


Start Ollama:

ollama serve

### **3ï¸âƒ£ Setup the Backend (Local Server)**

Go to your server directory:

cd server
npm install
node server.js


If successful, youâ€™ll see:

âœ… Local AI server running on http://localhost:5050

### **4ï¸âƒ£ Setup Chrome Extension**

Open Google Chrome

Go to â†’ chrome://extensions/

Enable Developer mode

Click Load unpacked

Select the extension/ folder

Pin the ğŸ§  Mini AI Summarizer icon to your toolbar

5ï¸âƒ£ Test It Out

Open any article or blog

Click the ğŸ§  icon â†’ â€œSummarize Pageâ€

Wait a few secondsâ€¦

See your offline AI summary generated locally by Phi-3 ğŸš€

ğŸ§© Troubleshooting
Problem	Possible Fix
âŒ Backend error: Unexpected token '<'	Ensure your server is running at http://localhost:5050
âš ï¸ PayloadTooLargeError	Increase limit: app.use(express.json({ limit: "5mb" }))
ğŸš« Could not establish connection	Reload the tab or re-enable the extension
ğŸ§± model runner has unexpectedly stopped	Restart Ollama: killall ollama && ollama serve
ğŸ§  Future Enhancements

ğŸ’¬ Add multi-mode AI panel (Summarize / Explain / Simplify / Ask)

ğŸ—‚ï¸ Store summary history locally

ğŸ”Š Add â€œRead Aloudâ€ (TTS)

ğŸ¨ Sidebar UI (like Perplexity or Comet)

âš™ï¸ Model switcher for Phi-3 / Llama3 / Gemma2

ğŸ“œ License

MIT License Â© 2025 Yash Rawat

<p align="center"> <b>Made with â¤ï¸ and Phi-3 by Yash Rawat</b> </p> ```